{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Flatten, Dense,LayerNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy import argmax\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Remove columns where their last row is null\n",
    "    df = df.drop(columns=df.columns[df.iloc[-1].isnull()])\n",
    "\n",
    "    # Remove columns with more than 80% NaN values and fill others with mean\n",
    "    threshold = 0.8 * len(df)\n",
    "    df = df.dropna(thresh=threshold, axis=1)\n",
    "    df = df.fillna(df.mean())\n",
    "\n",
    "   # Compute the mean for each column\n",
    "    column_means = df.mean()\n",
    "    padding_len = 497 - len(df)\n",
    "# Create padding using the mean values\n",
    "    padding = pd.DataFrame([column_means] * padding_len)\n",
    "# Concatenate padding and the original DataFrame\n",
    "    df = pd.concat([padding, df], axis=0).reset_index(drop=True)\n",
    "   \n",
    "    return df\n",
    "\n",
    "def load_data(*files):\n",
    "    dataframes = []\n",
    "\n",
    "    for file in files:\n",
    "        # Load dataframe\n",
    "        df = pd.read_csv(file, header=0)\n",
    "        \n",
    "        # Preprocess the data\n",
    "        df = preprocess_data(df)\n",
    "        # Add a prefix to each column name based on the file name\n",
    "        prefix = file.split('.')[0]  # Assuming the file name is '11_2016.csv', this gets '11_2016'\n",
    "        df.columns = [f\"{prefix}_{col}\" for col in df.columns]\n",
    "        \n",
    "        # Reset index after preprocessing to ensure unique indices\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concatenate all preprocessed dataframes\n",
    "    result = pd.concat(dataframes, axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Build the LSTM model for multi-class classification\n",
    "def build_classifier_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=490, input_shape=(1, 496), return_sequences=True)))     \n",
    "    \n",
    "    # Add another LSTM layer with 120 units\n",
    "    model.add(LSTM(120, return_sequences=True))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # softmax for multi-class\n",
    "    model.compile(optimizer='rmsprop', loss=\"categorical_crossentropy\", metrics=['accuracy', f1_score])\n",
    "    return model\n",
    "\n",
    "# F1 Score Custom Metric\n",
    "def f1_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision_val = precision(y_true, y_pred)\n",
    "    recall_val = recall(y_true, y_pred)\n",
    "    return 2 * ((precision_val * recall_val) / (precision_val + recall_val + K.epsilon()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load data\n",
    "    files = ['11_2016.csv', '12_2016.csv', '01_2017.csv', '02_2017.csv', '03_2018.csv',\n",
    "             '12_2017.csv', '01_2018.csv', '02_2018.csv', '03_2018.csv']\n",
    "    df = load_data(*files)\n",
    "    df = df.T\n",
    "    # Setup KFold Cross Validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    f1scores = []\n",
    "\n",
    "    for train_index, test_index in kfold.split(df):\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Data preprocessing\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Convert y_train and y_test to categorical\n",
    "        y_train, y_test = y_train.astype(int), y_test.astype(int)\n",
    "        y_train = to_categorical(y_train, num_classes=7)\n",
    "        y_test = to_categorical(y_test, num_classes=7)\n",
    "\n",
    "        # Reshape data for LSTM\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        # Train the model\n",
    "        model = build_classifier_model(X_train.shape[2], 7)\n",
    "        model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=64, verbose=0)\n",
    "\n",
    "        # Evaluate the model\n",
    "        loss, accuracy, f1score = model.evaluate(X_test, y_test, verbose=0)\n",
    "        accuracies.append(accuracy)\n",
    "        f1scores.append(f1score)\n",
    "\n",
    "    print('Average Accuracy: %.2f%%' % (np.mean(accuracies) * 100))\n",
    "    print('Average F1 Score: %.2f' % np.mean(f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
